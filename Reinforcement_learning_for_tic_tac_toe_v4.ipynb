{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RussAbbott/TicTacToe/blob/master/Reinforcement_learning_for_tic_tac_toe_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWT1VgWH_58q"
      },
      "source": [
        "# Reinforcement learning for tic-tac-toe\n",
        "\n",
        "Based on Daniel Sauble's [article](https://medium.com/swlh/tic-tac-toe-and-deep-neural-networks-ea600bc53f51) and Github [repo](https://github.com/djsauble/tic-tac-toe-ai/blob/master/reinforcement_learning_for_tic-tac-toe.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5Kvru5Bk_58u"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "# import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.backend import reshape\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title class Config\n",
        "\n",
        "class Config:\n",
        "    '''\n",
        "    Static information and methods about the game\n",
        "    '''\n",
        "    def __init__(self, board_side=3):\n",
        "        self.board_side = board_side\n",
        "        self.triples = self.collect_the_triples()\n",
        "        self.x = 'X'\n",
        "        self.o = 'O'\n",
        "        self.empty = ' '\n",
        "        self.draw = 'Draw'\n",
        "\n",
        "    # v v v v v v v v v v v v v v v v v v staticmethod v v v v v v v v v v v v v v v v v v \n",
        "\n",
        "    @staticmethod\n",
        "    def tuple_board(board):\n",
        "        '''\n",
        "        Convert a 3x3 board into a 3-tuple of 3-tuples\n",
        "        '''\n",
        "        list_of_tuples = [tuple(row.tolist()) for row in board]\n",
        "        return tuple(list_of_tuples)\n",
        "\n",
        "    # ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ staticmethod ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ \n",
        "\n",
        "\n",
        "    def collect_the_triples(self):\n",
        "        '''\n",
        "        Generate all 3-in-a-row cell sequences\n",
        "        Each cell sequence will be returned as [(r, c), (r, c), (r, c)],\n",
        "        where the (r, c)'s are the cell coordinates. (Each cell will appear in a number of sequences.)\n",
        "        '''\n",
        "        row_triples = [[(r, c) for c in range(self.board_side)] for r in range(self.board_side)]\n",
        "        col_triples = [[(r, c)  for r in range(self.board_side)] for c in range(self.board_side)]\n",
        "        pos_diag = [(rc, rc) for rc in range(self.board_side)]                  # [(0, 0), (1, 1), (2, 2)]]\n",
        "        neg_diag = [(r, (self.board_side - 1) - r) for r in range(self.board_side)]  # [(0, 2), (1, 1), (2, 0)]]\n",
        "                        \n",
        "        all_triples = row_triples + col_triples + [pos_diag, neg_diag]\n",
        "        return all_triples\n",
        "\n",
        "\n",
        "    def new_board(self):\n",
        "        board = np.full( (self.board_side, self.board_side), self.empty, dtype='str')\n",
        "        return board\n",
        "\n",
        "\n",
        "    def normalize_board_state(self, board, board_state_mapping, board_states_seen):\n",
        "        '''\n",
        "        Input: a 3x3 board state\n",
        "        Output: the distinguished board state that represents the input board state\n",
        "        First check to see if the input board state already has an associated\n",
        "        distinguished board state. If so, return that distinguished board state.\n",
        "        If not, generate all 8 equivalent board states. Select one of the, arbitrarily\n",
        "        the smallest under < . Point all 8 board states to the distiguished board state.\n",
        "        Do all this with tuples because dictionaries require immutable keys.\n",
        "        '''\n",
        "        t_board = self.tuple_board(board)\n",
        "        # Include the tuple version of the board to board_states_seen\n",
        "        board_states_seen.add(t_board)\n",
        "        n_board = board_state_mapping.get(t_board)\n",
        "        if n_board is not None:\n",
        "            return n_board\n",
        "\n",
        "        t_boards = []\n",
        "        for _ in range(4):\n",
        "            t_boards.append(t_board)\n",
        "            t_boards.append(self.tuple_board(np.transpose(t_board)))\n",
        "            t_board = self.tuple_board(np.rot90(t_board))\n",
        "        min_board = min(t_boards)\n",
        "\n",
        "        for t_board in t_boards:\n",
        "            if t_board not in board_state_mapping:\n",
        "                board_state_mapping[t_board] = min_board\n",
        "\n",
        "        return min_board\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UqOU3vGiS6ZC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title class Game\n",
        "\n",
        "class Game:\n",
        "    '''\n",
        "    The dynamic information about the game along wihth link to Config()\n",
        "    '''\n",
        "    def __init__(self, x_strategy=None, o_strategy=None, verbose=False):\n",
        "        self.config = Config(board_side=3)\n",
        "        self.board = self.config.new_board()\n",
        "        self.board_history = []\n",
        "        self.active_mark = self.config.x\n",
        "        self.other_mark = self.config.o\n",
        "        self.active_strategy = x_strategy\n",
        "        self.other_strategy = o_strategy\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # # For minimax\n",
        "        # self.depth_limit = None\n",
        "        # self.depth = 0\n",
        "\n",
        "\n",
        "    # v v v v v v v v v v v v v v v v v v staticmethod v v v v v v v v v v v v v v v v v v \n",
        "\n",
        "    # ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ staticmethod ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ \n",
        "\n",
        "\n",
        "    def game_status(self, requested_counts={3: 0, 2: 0, 1: 0}):\n",
        "        '''\n",
        "        returns: game_over, counts\n",
        "\n",
        "        The counts are dictionary items() of numbers of triples with exactly 1, 2, or 3 of a kind with the rest blanks.\n",
        "        The o's counts are counted negatively to facilitate minimax.\n",
        "        '''\n",
        "        triples = self.config.triples\n",
        "        counts = requested_counts.copy()\n",
        "        any_triples_in_play = False\n",
        "        x = self.config.x\n",
        "        o = self.config.o\n",
        "\n",
        "\n",
        "        for triple in triples:\n",
        "            triple_with_values = [self.board[r][c] for (r, c) in triple]\n",
        "            xs_in_triple, os_in_triple = triple_with_values.count(x), triple_with_values.count(o)\n",
        "\n",
        "            # A triple is in play if it has no more than one player and that player has not won the triple\n",
        "            \n",
        "            # The following is about the |= (in-place 'or') operation.\n",
        "            # |= does not short-circuit even if the LHS is already true. That is,\n",
        "            #                   x |= expression\n",
        "            # will evaluate expression even if x is already true. Hence:\n",
        "            if not any_triples_in_play:\n",
        "                any_triples_in_play = ( \n",
        "                                        (xs_in_triple == 0 or os_in_triple == 0) and\n",
        "                                        (xs_in_triple + os_in_triple < 3)\n",
        "                                      )\n",
        "\n",
        "            for count in requested_counts:\n",
        "                if xs_in_triple == count and os_in_triple == 0: \n",
        "                    counts[count] += 1\n",
        "\n",
        "                # Count the opponents scores negatively\n",
        "                if os_in_triple == count and xs_in_triple == 0: \n",
        "                    counts[count] -= 1\n",
        "\n",
        "        game_over = counts[3] != 0 or not any_triples_in_play\n",
        "\n",
        "        return game_over, list(counts.items())\n",
        "\n",
        "\n",
        "    def get_winner(self, counts):\n",
        "        '''\n",
        "        Called when the game is known to be over. Returns either config.x or config.o if there is\n",
        "        a winner, or config.draw if the game is a draw.\n",
        "        '''\n",
        "        winner = self.config.x if counts[3] > 0 else self.config.o if counts[3] < 0 else self.config.draw\n",
        "        return winner\n",
        "\n",
        "        \n",
        "    def moves_to_board(self, moves, verbose=False):\n",
        "        '''\n",
        "        Reconstruct the board from a list of moves.\n",
        "        This is run in a new and independent Game\n",
        "        '''\n",
        "        for player, (row, col) in moves:\n",
        "            self.board[row, col] = player\n",
        "            if verbose:\n",
        "                game.print_board()\n",
        "                print('\\n')\n",
        "\n",
        "\n",
        "    def print_board(self, title=''):\n",
        "        '''\n",
        "        Print either the current board or a supplied board\n",
        "        '''\n",
        "        # player_symbol = config.player_symbol\n",
        "        rows = 'ABC'\n",
        "        print(f'\\n{title}')\n",
        "        print('    1   2   3')\n",
        "        for r in range(len(self.board)):\n",
        "            print(f' {rows[r]} ', end='')\n",
        "            for c in range(len(self.board[r])):\n",
        "            #     mark = player_symbol[board[r][c]]\n",
        "                mark = ' ' + self.board[r][c] + ' '\n",
        "                last_in_row = c == len(self.board[r]) - 1\n",
        "                print(f'{mark}{\"\" if last_in_row else \"|\"}', end='\\n' if last_in_row else '')\n",
        "            if (r < len(self.board) - 1):\n",
        "                print(\"   -----------\")\n",
        "\n",
        "        game_over, counts = self.game_status()\n",
        "        if game_over:\n",
        "            winner = self.get_winner(dict(counts))\n",
        "            caption = '     ' + ((winner + \" wins\") if winner in [self.config.x, self.config.o] else (' ' + winner))\n",
        "            dots = \"   ...........\"\n",
        "            print(dots)\n",
        "            print(caption)\n",
        "            print(dots)\n",
        "\n",
        "    def switch_active_player(self):\n",
        "        # This does the right thing. The RHS is fully evaluated before assignment to the LHS.\n",
        "        self.active_mark, self.other_mark = self.other_mark, self.active_mark\n",
        "        self.active_strategy, self.other_strategy = self.other_strategy, self.active_strategy\n"
      ],
      "metadata": {
        "id": "AY6O_8iTlVK4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test the Game class\n",
        "\n",
        "game = Game()\n",
        "\n",
        "x = game.config.x\n",
        "o = game.config.o\n",
        "\n",
        "history = [(x, (0, 0)), (x, (1, 1)), (x, (2, 2)), # X wins\n",
        "           (o, (2, 2)), (o, (1, 2)), (o, (0, 2)), # O wins\n",
        "           (x, (1, 2)), (o, (1, 0)), (x, (2, 1)), (o, (0, 1)), # Draw\n",
        "           ]\n",
        "\n",
        "game.moves_to_board(history, verbose=True)\n"
      ],
      "metadata": {
        "id": "mlimXsaRoAMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "H1NPSq8D_58y"
      },
      "outputs": [],
      "source": [
        "# @title class PlayableGame\n",
        "\n",
        "class PlayableGame(Game):\n",
        "\n",
        "    def __init__(self, x_strategy=None, o_strategy=None, verbose=False):\n",
        "        # For minimax\n",
        "        self.depth_limit = None\n",
        "        self.depth = 0\n",
        "        super().__init__(x_strategy=x_strategy, o_strategy=o_strategy, verbose=verbose)\n",
        "        \n",
        "    # v v v v v v v v v v v v v v v v v v staticmethod v v v v v v v v v v v v v v v v v v \n",
        "\n",
        "    @staticmethod\n",
        "    def cell_label(cell):\n",
        "        '''\n",
        "        Convert a zero-based (row, col) pair of coordinates to Letter-Number notation.\n",
        "        E.g., (0, 1) -> A2\n",
        "        '''\n",
        "        r, c = cell\n",
        "        return ['A', 'B', 'C'][r](c+1)\n",
        "                \n",
        "                \n",
        "    @staticmethod\n",
        "    def explain_move_input():\n",
        "        print(f'Indicate a move as follows.\\n')\n",
        "        print('   1     2    3')\n",
        "        print('A  A1 |  A2 | A3')\n",
        "        print('  ---------------')\n",
        "        print('B  B2 |  B2 | B3')\n",
        "        print('  ---------------')\n",
        "        print('C  C3 |  C2 | C3')\n",
        "        print('Lower case a, b, c may be used.\\n')\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def print_game_heading(x_strategy, o_strategy):\n",
        "        title = f'{x_strategy.__name__} (X) vs {o_strategy.__name__} (O)'\n",
        "        len_title = len(title)\n",
        "        dashes = '- '*(10 + len_title//2 + (1 if len_title%2==1 else 0))\n",
        "        print(f'\\n\\n' + dashes)\n",
        "        print(f'{\" \"*10}{title}')\n",
        "        print(dashes + '\\n')\n",
        "\n",
        "    # ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ staticmethod ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ \n",
        "\n",
        "\n",
        "    def child_board(self, move):\n",
        "        '''\n",
        "        Put self.active_mark at (r, c) of a copy of board.\n",
        "        Return the updated board, but don't change self.board.\n",
        "        '''\n",
        "        next_board = self.board.copy()\n",
        "        r, c = move\n",
        "        next_board[r][c] = self.active_mark\n",
        "        return next_board\n",
        "\n",
        "\n",
        "    def game_stats(self, x_strategy, o_strategy, nbr_games, games):\n",
        "        '''\n",
        "        Aggregate win/loss/draw stats for a player\n",
        "        Input: a list of (move_history, board_history) pairs.\n",
        "        We ignore the move_history and look only at the final board_history\n",
        "        '''\n",
        "        if isinstance(x_strategy, Sequential):\n",
        "            x_strategy = self.model_strategy \n",
        "\n",
        "        if isinstance(o_strategy, Sequential):\n",
        "            o_strategy = self.model_strategy \n",
        "\n",
        "        print(f'X ({x_strategy.__name__}) vs O ({o_strategy.__name__}). {nbr_games} games.')\n",
        "\n",
        "        # Keep the stats from the perspective of the x player\n",
        "        stats = {\"x\": 0, \"o\": 0, \"draw\": 0}\n",
        "        for board_history in games:\n",
        "            _status, counts = self.game_status(board_history[-1])\n",
        "            counts = dict(counts)\n",
        "            if counts[3] > 0:\n",
        "                stats[\"x\"] += 1\n",
        "            elif counts[3] < 0:\n",
        "                stats[\"o\"] += 1\n",
        "            else:\n",
        "                stats[\"draw\"] += 1\n",
        "        \n",
        "        player_x_pct = stats[\"x\"] / len(games) * 100\n",
        "        player_o_pct = stats[\"o\"] / len(games) * 100\n",
        "        draw_pct = stats[\"draw\"] / len(games) * 100\n",
        "\n",
        "        print(\"Player\\twins\\tpct wins\")\n",
        "        print(\"------\\t----\\t--------\")\n",
        "        print(f\"   x\\t {stats['x']}\\t  {round(player_x_pct)}%\")\n",
        "        print(f\"   o\\t {stats['o']}\\t  {round(player_o_pct)}%\")\n",
        "        print(f\" Draws\\t {stats['draw']}\\t  {round(draw_pct)}%\")\n",
        "        print()\n",
        "\n",
        "\n",
        "    def get_user_move(self):\n",
        "        '''\n",
        "        Get the user's input and translate to zero-based (row, col)\n",
        "        '''\n",
        "        char_to_nbr = {'A': 0, 'B': 1, 'C': 2, 'a': 0, 'b': 1, 'c': 2, '1': 0, '2': 1, '3': 2}\n",
        "        \n",
        "        # Loop until the user produces a valid input. Return from within the loop.\n",
        "        while True:\n",
        "            strng = input(f'\\n{self.active_mark}\\'s move > ')\n",
        "            chars = [char_to_nbr[c] for c in strng if c in char_to_nbr]\n",
        "\n",
        "            if len(chars) != 2:\n",
        "                print('Invalid input')\n",
        "                continue\n",
        "\n",
        "            r, c = chars \n",
        "            cell = self.board[r][c]\n",
        "            # print(f'{strng = } {chars = } {(r, c)} {cell = } {self.config.empty = } {cell == self.config.empty = } ')\n",
        "            if cell == self.config.empty:\n",
        "                # print(f'Returning {(r, c)}')\n",
        "                return r, c\n",
        "            else:\n",
        "                print(f'Cell {strng} already contains {cell}\\n')\n",
        "                \n",
        "\n",
        "    def human_strategy(self):\n",
        "        '''\n",
        "        Get the user's row-col move in the form of A1, A2, A3, B1, B2, B3, C1, C2, C3.\n",
        "        A, B, C identifies the row; the number identifies the column.\n",
        "        Translate that to zero-based (row, col).\n",
        "        '''\n",
        "        print()\n",
        "        self.print_board()\n",
        "        r, c = self.get_user_move()\n",
        "        return r, c\n",
        "\n",
        "\n",
        "    def minimax_moves_and_score(self):\n",
        "        '''\n",
        "        Because the board and the active player change frequently, they are passed explicitly to the\n",
        "        minimax methods--rathan using the board and active_mark stored a self-values. \n",
        "\n",
        "        Given a board and given that this isn't a terminal node, use minimax to find and return:\n",
        "            (a) the minimax score for this board along with \n",
        "            (b) a list of moves that produce it.\n",
        "        Note: board may be down the tree from the current board stored at self.board.\n",
        "        '''\n",
        "        v_moves = self.valid_moves()\n",
        "        # For each valid move, find the minimax score for the board that that move produces.\n",
        "        # Use self.wrap_run_restore() to:\n",
        "        # (a) update the state, (b) run minimax_score() to find the minimax value, and (c) restore the state\n",
        "        switched_mark = self.config.x if self.active_mark == self.config.o else self.config.o \n",
        "        move_scores = [(move, self.wrap_run_restore(fn=self.minimax_score, \n",
        "                                                    next_depth=self.depth+1, \n",
        "                                                    next_board=self.child_board(move), \n",
        "                                                    next_mark=switched_mark))\n",
        "                      for move in v_moves]\n",
        "        # move_scores = [(move, self.minimax_score(depth-1, self.child_board(self.board, move, switched_mark)))\n",
        "        #               for move in v_moves]\n",
        "        # The player playing X is the maximizer.\n",
        "        is_maximizer = self.active_mark == self.config.x\n",
        "        min_or_max = max if is_maximizer else min\n",
        "        # Initially, we ignore the specific move that prodocued the best score.\n",
        "        _best_move, best_score = min_or_max(move_scores, key=lambda m_s: m_s[1])\n",
        "\n",
        "\n",
        "        # If we are at the top level, print the various moves and the scores they produce.\n",
        "        # Mark the ones that are the best score.\n",
        "        if self.verbose and self.depth == 0:\n",
        "            # print(f\"\\n\\nplayer = {config.player_symbol[player][1]}.\")\n",
        "            self.print_board(title=f\"\\n\\n{self.active_strategy = }.\")\n",
        "            print()\n",
        "            for move, score in move_scores:\n",
        "                # move is the (row, col) pair to be occupied by this move\n",
        "                # Since (row, col) is zero-based, translate to the notation used for human play.\n",
        "                print(f\"{self.cell_label(move)} -> {score} {' (ok)' if score == best_score else ''}\")\n",
        "            print(f\"{best_moves = }\")\n",
        "\n",
        "        # Find all the moves that produce that best score.\n",
        "        best_moves = [move for move, score in move_scores if score == best_score]\n",
        "\n",
        "        return best_moves, best_score\n",
        "\n",
        "\n",
        "    def minimax_score(self):\n",
        "        '''\n",
        "        Returns the minimax score for board.\n",
        "        '''\n",
        "        # Evaluate the game at its current state\n",
        "        game_over, score = self.game_status()\n",
        "        # If at a terminal node, i.e., if self.depth = self.depth_limit or game_over, \n",
        "        # keep this score and return it as the score value.\n",
        "        # Otherwise,\n",
        "        if self.depth != self.depth_limit and not game_over:\n",
        "            # call minimax recursively to get the score.    \n",
        "            _moves, score = self.minimax_moves_and_score()\n",
        "        \n",
        "        return score\n",
        "\n",
        "\n",
        "    def minimax_strategy(self, depth_limit):\n",
        "        # If minimax is playing X, select a corner as a first move.\n",
        "        # (This is hard-wired. The scoring algorithm would select the center square.)\n",
        "        if np.count_nonzero(self.board==self.config.empty) == 9:\n",
        "            return random.choice([(0, 0), (0, 2), (2, 0), (2, 2)]) \n",
        "\n",
        "        self.depth_limit = depth_limit\n",
        "        moves, _score = self.minimax_moves_and_score()\n",
        "        move = random.choice(moves)\n",
        "        return move\n",
        "\n",
        "\n",
        "    def model_strategy(self, model, rnd=0):\n",
        "        '''\n",
        "        Use the model to get the best next move for the given player at the given board position\n",
        "        '''\n",
        "        scores = []\n",
        "        v_moves = self.valid_moves(game.board, config.empty)\n",
        "        # Make predictions for each possible move\n",
        "        if self.verbose:\n",
        "            print('\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
        "        for row, col in v_moves:\n",
        "            # row, col = v_moves[i]\n",
        "            next_board = np.array(game.board)\n",
        "            next_board[row][col] = game.active_mark\n",
        "            next_board_1d = next_board.reshape((-1, 9))\n",
        "            prediction = model.predict(next_board_1d)[0]\n",
        "            np.around(prediction, 2, out=prediction)\n",
        "            if self.verbose:\n",
        "                self.print_board(next_board, config, title=f'If {self.active_mark} moves to {self.cell_label((row, col))}:')\n",
        "                for label, prob in zip([\"Draw\", \"X wins\", \"O wins\"], prediction):\n",
        "                    print(f'{label} = {prob}')\n",
        "\n",
        "            if game.active_mark == self.config.x:\n",
        "                draw_prediction, win_prediction, loss_prediction = prediction\n",
        "            elif game.active_mark == self.config.o:\n",
        "                draw_prediction, loss_prediction, win_prediction = prediction\n",
        "            else:\n",
        "                message = f'The active_mark ({self.active_mark}) is neither {self.config.x} nor {self.config.o}.\\n' \n",
        "                raise Exception(message)\n",
        "\n",
        "            if win_prediction > loss_prediction:\n",
        "                scores.append(win_prediction - loss_prediction)\n",
        "            else:\n",
        "                scores.append(draw_prediction - loss_prediction)\n",
        "\n",
        "        # Choose the best move with a random factor\n",
        "        best_moves_indices = np.flip(np.argsort(scores))\n",
        "        move = None\n",
        "        for i in range(len(best_moves_indices)):\n",
        "            if random.random() * rnd < 0.5:\n",
        "                move = v_moves[best_moves_indices[i]]\n",
        "\n",
        "        if move == None:\n",
        "            # Choose a move at random\n",
        "            move = random.choice(v_moves)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f'\\n==> {self.active_mark} moves to {move}.')\n",
        "            print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
        "\n",
        "        return move\n",
        "\n",
        "\n",
        "    def play_a_game(self, x_strategy, o_strategy, verbose=False, rnd=0):\n",
        "        '''\n",
        "        Play a game.\n",
        "        '''\n",
        "        super().__init__(x_strategy, o_strategy, verbose=verbose)\n",
        "\n",
        "        human_is_playing = self.human_strategy in [x_strategy, o_strategy]\n",
        "\n",
        "        if human_is_playing:\n",
        "            self.print_game_heading(x_strategy, o_strategy)\n",
        "            # print(f'\\n\\n{game.active_strategy.__name__} (X) vs {game.other_strategy.__name__} (O)\\n\\n')\n",
        "            self.explain_move_input()\n",
        "\n",
        "        # game_status returns (status, score), where status is True/False depending on whether the game is over. \n",
        "        # So, the followinhg line says: repeat this loop as long as status is not True, i.e., game_over.\n",
        "        while not self.game_status()[0]:\n",
        "\n",
        "            row, col = self.select_a_move(rnd=rnd)\n",
        "            # Make the move\n",
        "            self.board[row][col] = self.active_mark\n",
        "\n",
        "            # Add the board to board_history\n",
        "            self.board_history.append(self.board.copy())\n",
        "            \n",
        "            # Switch the active player\n",
        "            self.switch_active_player()\n",
        "\n",
        "        if human_is_playing:\n",
        "            self.print_board(title='\\n    Game over\\n   ...........')\n",
        "                    \n",
        "\n",
        "    def random_strategy(self):\n",
        "        '''\n",
        "        Return a random (valid) move\n",
        "        '''\n",
        "        v_moves = self.valid_moves()\n",
        "        move = random.choice(v_moves)\n",
        "        return move\n",
        "\n",
        "\n",
        "    def select_a_move(self, rnd=0):\n",
        "        '''\n",
        "        Let self.active_strategy select a move.\n",
        "        '''\n",
        "        if isinstance(self.active_strategy, Sequential):\n",
        "            # In this case, self.active_strategy is the trained model rather than a \"strategy.\". \n",
        "            # Pass the model to model_strategy().\n",
        "            model = self.active_strategy\n",
        "            return self.model_strategy(model, rnd=rnd)\n",
        "\n",
        "        if self.active_strategy == self.human_strategy:\n",
        "            return self.human_strategy()\n",
        "\n",
        "        if self.active_strategy in [self.minimax_strategy, self.win_block_strategy]:\n",
        "            depth = 1 if self.active_strategy == self.win_block_strategy else 5\n",
        "            return self.minimax_strategy(depth)\n",
        "\n",
        "        return self.random_strategy()\n",
        "\n",
        "\n",
        "    def valid_moves(self):\n",
        "        '''\n",
        "        Get a list of valid moves.\n",
        "        '''\n",
        "        board_side = self.config.board_side\n",
        "        empty = self.config.empty\n",
        "        moves = [(r, c) for r in range(board_side) \n",
        "                        for c in range(board_side) \n",
        "                        if self.board[r][c] == empty]\n",
        "        return moves\n",
        "\n",
        "\n",
        "    def win_block_strategy(self, depth=1):\n",
        "        '''\n",
        "        The win_block_strategy is a minimax player limited to a search depth of 1.\n",
        "        In other words, it looks ahead one move: what will its current move yield?\n",
        "        \n",
        "        This lets it determine whether it can win on its current move. \n",
        "        \n",
        "        It also allows it to determine whether it is leaving the other player \n",
        "        2 in a row, which will let the other player win on its next move.\n",
        "        '''\n",
        "        return self.minimax_strategy(depth)\n",
        "\n",
        "    \n",
        "    def wrap_run_restore(self, fn, next_depth, next_board, next_mark):\n",
        "        # Save the current depth, board and active_mark\n",
        "        current_depth, current_board, current_mark = self.depth, self.board, self.active_mark\n",
        "\n",
        "        # Update the state\n",
        "        self.depth, self.board, self.active_mark = next_depth, next_board, next_mark\n",
        "\n",
        "        # Call the function\n",
        "        result = fn()\n",
        "\n",
        "        # Restore the state\n",
        "        self.depth, self.board, self.active_mark = current_depth, current_board, current_mark\n",
        "\n",
        "        # Return the result\n",
        "        return result\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "R7_sPT5X_58z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82163d23-92b5-4b52-9531-501c92832cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "          random_strategy (X) vs win_block_strategy (O)\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "\n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A    | X |   \n",
            "   -----------\n",
            " B    |   |   \n",
            "   -----------\n",
            " C    |   |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A    | X |   \n",
            "   -----------\n",
            " B    | O |   \n",
            "   -----------\n",
            " C    |   |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A    | X |   \n",
            "   -----------\n",
            " B  X | O |   \n",
            "   -----------\n",
            " C    |   |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A    | X | O \n",
            "   -----------\n",
            " B  X | O |   \n",
            "   -----------\n",
            " C    |   |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A    | X | O \n",
            "   -----------\n",
            " B  X | O |   \n",
            "   -----------\n",
            " C    |   | X \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A    | X | O \n",
            "   -----------\n",
            " B  X | O |   \n",
            "   -----------\n",
            " C  O |   | X \n",
            "   ...........\n",
            "     O wins\n",
            "   ...........\n",
            "\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "          win_block_strategy (X) vs minimax_strategy (O)\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "\n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A  X |   |   \n",
            "   -----------\n",
            " B    |   |   \n",
            "   -----------\n",
            " C    |   |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A  X |   |   \n",
            "   -----------\n",
            " B    | O |   \n",
            "   -----------\n",
            " C    |   |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A  X |   | X \n",
            "   -----------\n",
            " B    | O |   \n",
            "   -----------\n",
            " C    |   |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A  X | O | X \n",
            "   -----------\n",
            " B    | O |   \n",
            "   -----------\n",
            " C    |   |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A  X | O | X \n",
            "   -----------\n",
            " B    | O |   \n",
            "   -----------\n",
            " C    | X |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A  X | O | X \n",
            "   -----------\n",
            " B    | O | O \n",
            "   -----------\n",
            " C    | X |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A  X | O | X \n",
            "   -----------\n",
            " B  X | O | O \n",
            "   -----------\n",
            " C    | X |   \n",
            "\n",
            "\n",
            "    1   2   3\n",
            " A  X | O | X \n",
            "   -----------\n",
            " B  X | O | O \n",
            "   -----------\n",
            " C  O | X |   \n",
            "   ...........\n",
            "      Draw\n",
            "   ...........\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8a9c121c9596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
          ]
        }
      ],
      "source": [
        "#@title test Playable_Game\n",
        "\n",
        "random.seed()\n",
        "\n",
        "game = PlayableGame()\n",
        "\n",
        "for x_strategy, o_strategy in  [\n",
        "                                # (game.random_strategy, game.random_strategy), \n",
        "                                # (game.random_strategy, game.human_strategy),  \n",
        "                                # (game.human_strategy, game.random_strategy),\n",
        "                                (game.random_strategy, game.win_block_strategy),\n",
        "                                (game.win_block_strategy, game.minimax_strategy),\n",
        "                                ]:\n",
        "    game.play_a_game(x_strategy=x_strategy, o_strategy=o_strategy)\n",
        "\n",
        "    if game.human_strategy not in [x_strategy, o_strategy]:\n",
        "        game.print_game_heading(x_strategy, o_strategy)\n",
        "\n",
        "        for game.board in game.board_history:\n",
        "            game.print_board()\n",
        "\n",
        "stop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class B:\n",
        "\n",
        "    def fn_b():\n",
        "        class_a = A()\n",
        "        print('fn_b: Calling class_a.fn_a1(class_a)')\n",
        "        class_a.fn_a1(class_a)\n",
        "        # print('fn_b: Calling A.fn_a1(class_a)')\n",
        "        # A.fn_a1(class_a)\n",
        "\n",
        "class A:\n",
        "\n",
        "    @staticmethod\n",
        "    def fn_a1(gme):\n",
        "        print(f'\\nfn_a1: {gme = }. Calling gme.fn_a2b()')\n",
        "        gme.fn_a2b()\n",
        "        print(f'\\nfn_a1: {gme = }. Calling A.fn_a2b(gme)')\n",
        "        A.fn_a2b(gme)\n",
        "\n",
        "    def fn_a2a(self):\n",
        "        print(f'fn_a2a: {self = }')\n",
        "\n",
        "    def fn_a2b(gme):\n",
        "        print(f'fn_a2b: {gme = }, Calling gme.fn_a3(gme.fn_a2a)')\n",
        "        gme.fn_a3(gme.fn_a2a)\n",
        "\n",
        "    @staticmethod\n",
        "    def fn_a3(fn):\n",
        "        print(f'fn_a3: {fn = }. Calling fn()')\n",
        "        fn()\n",
        "\n",
        "B.fn_b()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwm4Dt4VjUW-",
        "outputId": "33129e49-6ff5-4f90-e5ab-628309095704"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fn_b: Calling class_a.fn_a1(class_a)\n",
            "\n",
            "fn_a1: gme = <__main__.A object at 0x7fc2cc271700>. Calling gme.fn_a2b()\n",
            "fn_a2b: gme = <__main__.A object at 0x7fc2cc271700>, Calling gme.fn_a3(gme.fn_a2a)\n",
            "fn_a3: fn = <bound method A.fn_a2a of <__main__.A object at 0x7fc2cc271700>>. Calling fn()\n",
            "fn_a2a: self = <__main__.A object at 0x7fc2cc271700>\n",
            "\n",
            "fn_a1: gme = <__main__.A object at 0x7fc2cc271700>. Calling A.fn_a2b(gme)\n",
            "fn_a2b: gme = <__main__.A object at 0x7fc2cc271700>, Calling gme.fn_a3(gme.fn_a2a)\n",
            "fn_a3: fn = <bound method A.fn_a2a of <__main__.A object at 0x7fc2cc271700>>. Calling fn()\n",
            "fn_a2a: self = <__main__.A object at 0x7fc2cc271700>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8Ktc2DQ_58z"
      },
      "outputs": [],
      "source": [
        "# @title  Generate a collection of simulated games to calculate win/lose statistics for first and second players--and later to train our neural network. \n",
        "# 'X' (player 1) should have an edge due to first mover advantage.\n",
        "\n",
        "\n",
        "game = Game()\n",
        "x_strategy, o_strategy, nbr_games = game.random_strategy, game.random_strategy, 1000\n",
        "games_rr = [game.play_a_game(x_strategy=x_strategy, o_strategy=o_strategy) for _ in range(nbr_games)] \n",
        "game_stats(x_strategy, o_strategy, nbr_games, games_rr)\n",
        "\n",
        "x_strategy, o_strategy, nbr_games = game.win_block_strategy, game.random_strategy, 100\n",
        "games_wr = [game.play_a_game(x_strategy=x_strategy, o_strategy=o_strategy) for _ in range(nbr_games)] \n",
        "game_stats(x_strategy, o_strategy, nbr_games, games_wr)\n",
        "\n",
        "x_strategy, o_strategy, nbr_games = game.random_strategy, game.win_block_strategy, 100\n",
        "games_rw = [game.play_a_game(x_strategy=x_strategy, o_strategy=o_strategy) for _ in range(nbr_games)] \n",
        "game_stats(x_strategy, o_strategy, nbr_games, games_rw)\n",
        "\n",
        "games = games_rr + games_wr*10 + games_rw*10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Functions to normalize and label game states.\n",
        "\n",
        "# def tuple_board(board):\n",
        "#     '''\n",
        "#     Convert a 3x3 board into a 3-tuple of 3-tuples\n",
        "#     '''\n",
        "#     list_of_tuples = [tuple(row.tolist()) for row in board]\n",
        "#     return tuple(list_of_tuples)\n",
        "\n",
        "\n",
        "# def normalize_board_state(board, board_state_mapping, board_states_seen):\n",
        "#     '''\n",
        "#     Input: a 3x3 board state\n",
        "#     Output: the distinguished board state that represents the input board state\n",
        "#     First check to see if the input board state already has an associated\n",
        "#     distinguished board state. If so, return that distinguished board state.\n",
        "#     If not, generate all 8 equivalent board states. Select one of the, arbitrarily\n",
        "#     the smallest under < . Point all 8 board states to the distiguished board state.\n",
        "#     Do all this with tuples because dictionaries require immutable keys.\n",
        "#     '''\n",
        "#     t_board = tuple_board(board)\n",
        "#     # Include the tuple version of the board to board_states_seen\n",
        "#     board_states_seen.add(t_board)\n",
        "#     n_board = board_state_mapping.get(t_board)\n",
        "#     if n_board is not None:\n",
        "#         return n_board\n",
        "\n",
        "#     t_boards = []\n",
        "#     for _ in range(4):\n",
        "#         t_boards.append(t_board)\n",
        "#         t_boards.append(tuple_board(np.transpose(t_board)))\n",
        "#         t_board = tuple_board(np.rot90(t_board))\n",
        "#     min_board = min(t_boards)\n",
        "\n",
        "#     for t_board in t_boards:\n",
        "#         if t_board not in board_state_mapping:\n",
        "#             board_state_mapping[t_board] = min_board\n",
        "\n",
        "#     return min_board\n",
        "\n",
        "\n",
        "def board_history_to_labelled_board_states(board_history, board_state_mapping, board_states_seen):\n",
        "    '''\n",
        "    Input: a list of board positions for a game.\n",
        "    Output: a list of pairs, where each board position is paired with (labeled by) the winner of the game.\n",
        "    In the code above, a win by o is indicated by -1; a draw is indicated by 0; a win by x is indicated by 1.\n",
        "    However, we will use a neural net that maps board states to categories. Categories must be\n",
        "    non-negative integers. So we map (-1, 0, 1) -> (2, 0, 1) for category designation. \n",
        "    '''\n",
        "\n",
        "    # Get a list of normalizezd board states for the states in board_history. \n",
        "    # See normalize_board_state() for what that means.\n",
        "    normalized_board_states = [normalize_board_state(board, board_state_mapping, board_states_seen) for board in board_history]\n",
        "\n",
        "    # Get the winner of the board_history by looking at the final board in board_history.\n",
        "    _status, counts_as_tuples = game_status(board_history[-1], config)\n",
        "    winner = get_winner(dict(counts_as_tuples), config)\n",
        "    \n",
        "    # winner will be:config.x, config.o, or config.draw\n",
        "    # convert the winner to: {draw: 0; x won: 1, o_won: 2}; \n",
        "    # In categorical learning, the categories must all be non-negative integers\n",
        "    winner_to_category = {config.draw: 0, config.x: 1, config.o: 2}\n",
        "    winner_category = winner_to_category[winner]\n",
        "\n",
        "    # Make a list of the winner category as long as the board_history\n",
        "    list_of_winner_category = [winner_category] * len(board_history)\n",
        "    # Zip the two lists together and return the result.\n",
        "    return zip(normalized_board_states, list_of_winner_category)\n",
        "\n",
        "\n",
        "def labeled_and_shuffled_game_histories(games):\n",
        "    '''\n",
        "    Input: a list of (move_history, board_history) pairs, one for each game.\n",
        "\n",
        "    Produce a collection of board states labelled by who eventually won that game.\n",
        "    Return X y where X and y are lists of board states and the correspoding labels/categories.\n",
        "    The variable names X and y are the names used traditionally. X is upper case.\n",
        "\n",
        "    1. Ignore move_history. Work only with board_history\n",
        "    2. Use the last element in board_history to determine the game winner.\n",
        "    3. Pair each board position in board_history with that winner as a category/label.\n",
        "    4. Append the list of board positions to X and a list of length len(board_history) of winner to y   \n",
        "    5. Shuffle X and y simultaneously so that the labelled board posistions are spread around. \n",
        "    '''\n",
        "\n",
        "    # Because of symmetry, for every board state there are 7 equivalent board states. \n",
        "    # Select one of the 8 to represent them all.\n",
        "    # Store the mapping from board_state to distinguished board_state in the following cache (dictionary).\n",
        "    # Also use the dictionary to store the count of distinct board states.\n",
        "    board_state_mapping = {}\n",
        "    board_states_seen = set()\n",
        "\n",
        "    # Will be a list of (board_position, label) pair.\n",
        "    shuffled_Xs_ys = []\n",
        "\n",
        "    for _move_history, board_history in games:\n",
        "        shuffled_Xs_ys_for_a_game = board_history_to_labelled_board_states(board_history, board_state_mapping, board_states_seen)\n",
        "        shuffled_Xs_ys += shuffled_Xs_ys_for_a_game\n",
        "\n",
        "    # Shuffle the (board_position, winner) pairs so that not all the winners/losers occur first.\n",
        "    # random.shuffle shuffles a list in place\n",
        "    random.shuffle(shuffled_Xs_ys)\n",
        "\n",
        "    print(f'A simple upper bound for the size of the tic-tac-toe state space is {3**9 = }. ')\n",
        "    print('(Three states for each cell and nine cells.) ')\n",
        "    print('This count includes many illegal positions, such as a position with five Xs and no Os')\n",
        "    print('or a position in which both players have a row of three.\\n')\n",
        "    print('A more careful count, removing these illegal positions, gives 5,478.')\n",
        "    print('When rotations and reflections are considered, there are 765 different positions.')\n",
        "    print('Wikipedia: https://en.wikipedia.org/w/index.php?title=Game_complexity&oldid=950763371#Example:_tic-tac-toe_(noughts_and_crosses)\\n')\n",
        "\n",
        "    print(f'Summary. Valid board states: 5478.  After considering symmetries: 765.\\n')\n",
        "    print(f'Board states seen: {len(board_states_seen)}. Number of distinguished boards: {len(set(board_state_mapping.values()))} ')\n",
        "\n",
        "    return shuffled_Xs_ys\n",
        "\n",
        "\n",
        "\n",
        "def unzip(zipped):\n",
        "    [a, b] = zip(*zipped)\n",
        "    return list(a), list(b)    \n",
        "        \n",
        "    \n"
      ],
      "metadata": {
        "id": "Yz4oWy_L2QXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Label the board postions in the games abd shuffkle the labelled pairs.\n",
        "\n",
        "shuffled_Xs_ys = labeled_and_shuffled_game_histories(games)\n",
        "\n",
        "X, y = unzip(shuffled_Xs_ys)\n",
        "\n",
        "X = np.array(X).reshape((-1, 9))\n",
        "y = to_categorical(y, num_classes=3)\n",
        "\n",
        "# Split out the train and test data\n",
        "trainNum = int(len(X) * 0.8)\n",
        "X_train, X_test, y_train, y_test = X[:trainNum], X[trainNum:], y[:trainNum], y[trainNum:]\n"
      ],
      "metadata": {
        "id": "VfR-MUEDXnJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ztiJQrj_580"
      },
      "outputs": [],
      "source": [
        "#@title Prepare the neural net.\n",
        "\n",
        "def build_model(board_side):\n",
        "    '''\n",
        "    Create a NN model\n",
        "    '''\n",
        "    num_cells = board_side * board_side\n",
        "    outcomes = 3 # The number of possible outcomes in a game. (draw, X-wins, O-wins)\n",
        "    model = Sequential([\n",
        "                        Dense(200, input_shape=(num_cells, ), activation='relu'),\n",
        "                        Dropout(0.2),\n",
        "                        Dense(125, activation='relu'),\n",
        "                        Dense(75, activation='relu'),\n",
        "                        Dropout(0.1),\n",
        "                        Dense(25, activation='relu'),\n",
        "                        Dense(outcomes, activation='softmax'),\n",
        "                        ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "    print(model.summary())    \n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guG51x1C_581"
      },
      "outputs": [],
      "source": [
        "#@title Train the model on the tic-tac-toe games  generated earlier.\n",
        "\n",
        "game = Game()\n",
        "model = build_model(game.config.board_side)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "n_epochs = 500\n",
        "batch_size = 100\n",
        "\n",
        "# history output is not used\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=n_epochs, batch_size=batch_size)\n",
        "print('\\n\\tThe model is trained\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHJybhIy_581"
      },
      "outputs": [],
      "source": [
        "# @title First play a random player against itself and then the model against a random player.\n",
        "\n",
        "x_strategy = random_strategy\n",
        "o_strategy = random_strategy\n",
        "nbr_games = 1000\n",
        "games_rr = [play_a_game(x_strategy=x_strategy, o_strategy=o_strategy) for _ in range(nbr_games)]\n",
        "game_stats(x_strategy, o_strategy, nbr_games, games_rr)\n",
        "\n",
        "x_strategy = model\n",
        "o_strategy = random_strategy\n",
        "nbr_games = 100\n",
        "games_mr = [play_a_game(x_strategy=x_strategy, o_strategy=o_strategy) for _ in range(nbr_games)]\n",
        "game_stats(x_strategy, o_strategy, nbr_games, games_mr)\n",
        "\n",
        "x_strategy = random_strategy\n",
        "o_strategy = model\n",
        "nbr_games = 100\n",
        "games_rm = [play_a_game(x_strategy=x_strategy, o_strategy=o_strategy) for _ in range(nbr_games)]\n",
        "game_stats(x_strategy, o_strategy, nbr_games, games_rm)\n",
        "\n",
        "x_strategy = model\n",
        "o_strategy = model \n",
        "nbr_games = 100\n",
        "games_mm = [play_a_game(x_strategy=x_strategy, o_strategy=o_strategy) for _ in range(nbr_games)]\n",
        "game_stats(x_strategy, o_strategy, nbr_games, games_mm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPkNknoW_582"
      },
      "source": [
        "* In the original the random player won 76% of games as x; the model won 98%\n",
        "\n",
        "* In the original the random player won 48% of games as o; the model won 96%.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_strategy = human_strategy\n",
        "o_strategy = model \n",
        "_ = play_a_game(x_strategy=x_strategy, o_strategy=o_strategy, verbose=True)\n"
      ],
      "metadata": {
        "id": "TYud8ljySiCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dffNdbrq_582"
      },
      "source": [
        "* We see that the game tends toward a draw, which is what we would expect from a couple of human players. Still, neither player is particularly good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57xxBwxy_583"
      },
      "source": [
        "* As a final measure of skill, let's see how the length of the average game has changed. We would expect this to go down with an increased imbalance in skill levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kKldABg_583"
      },
      "outputs": [],
      "source": [
        "# @title Compare the lengths of the games\n",
        "\n",
        "def avg_game_length(games, prec=1):\n",
        "    lengths_as_floats = [float(len(game)) for game in games]\n",
        "    avg = np.mean(lengths_as_floats)\n",
        "    return round(avg, prec)\n",
        "\n",
        "print(f\"Average length of fully random game is {avg_game_length(games)} moves\")\n",
        "print(f\"Average length of game where x uses NN is {avg_game_length(games3)} moves\")\n",
        "print(f\"Average length of game where o uses NN is {avg_game_length(games4)} moves\")\n",
        "print(f\"Average length of game where both use NN is {avg_game_length(games5} moves\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02iONdim_583"
      },
      "source": [
        "* As shown above, the games are a move shorter for player 1 and a bit longer for player 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMS8B0Om_583"
      },
      "source": [
        "* Now, we play a game against our model and see how well it does. We let it make the first move."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS2D9ISl_580"
      },
      "source": [
        "* We choose a DNN architecture since we effectively want to predict the outcome of a game based on the given board state.\n",
        "* The input for each cell is the board state, which we reshape into a flat array of 9 elements, each element of which can be a 0 (empty cell), 1 (player 1 move), or 2 (player 2 move).\n",
        "* The output is the result of the game (win, loss, or draw). We use a one-hot encoded array for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgZSGn7Z_583"
      },
      "outputs": [],
      "source": [
        "# @title A human against the model\n",
        "\n",
        "x_strategy = human_strategy\n",
        "o_strategy = model\n",
        "play_a_game(x_strategy=x_strategy, o_strategy=o_strategy, rnd=0.6)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xahAIx2Q5n8y"
      },
      "outputs": [],
      "source": [
        "# @title A human against the model\n",
        "\n",
        "x_strategy = model\n",
        "o_strategy = human_strategy \n",
        "play_a_game(x_strategy=x_strategy, o_strategy=o_strategy, rnd=0.6)\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}